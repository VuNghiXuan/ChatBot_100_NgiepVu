"""1. File main.py (Tráº¡m Ä‘iá»u khiá»ƒn trung tÃ¢m)"""
import streamlit as st
from dotenv import load_dotenv
import os

# Import cÃ¡c thÃ nh pháº§n cá»‘t lÃµi
from core.llm_factory import LLMFactory
from core.orchestrator import Orchestrator

# 1. Cáº¥u hÃ¬nh giao diá»‡n vÃ  load biáº¿n mÃ´i trÆ°á»ng
load_dotenv()
st.set_page_config(page_title="AI Tiá»‡m VÃ ng - Enterprise Agent", layout="wide")

def init_system():
    """Khá»Ÿi táº¡o bá»™ nÃ£o cá»§a há»‡ thá»‘ng"""
    # Khá»Ÿi táº¡o model AI (Máº·c Ä‘á»‹nh dÃ¹ng Gemini)
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        st.error("Thiáº¿u GOOGLE_API_KEY trong file .env hoáº·c cáº¥u hÃ¬nh!")
        st.stop()
        
    llm = LLMFactory.get_model("Gemini", api_key)
    
    # Khá»Ÿi táº¡o bá»™ Ä‘iá»u phá»‘i (ÄÃ£ bao gá»“m Router vÃ  Connector bÃªn trong)
    return Orchestrator(llm)

# --- GIAO DIá»†N NGÆ¯á»œI DÃ™NG (UI) ---

st.title("ğŸ¤– Trá»£ LÃ½ AI Tiá»‡m VÃ ng Äa Nghiá»‡p Vá»¥")
st.markdown("---")

# Sidebar cáº¥u hÃ¬nh
with st.sidebar:
    st.header("âš™ï¸ Cáº¥u hÃ¬nh há»‡ thá»‘ng")
    st.info("Há»‡ thá»‘ng Ä‘ang cháº¡y cháº¿ Ä‘á»™ **Hybrid Mode** (Tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i File/DB/API)")
    
    if st.button("ğŸ”„ LÃ m má»›i bá»™ chá»‰ má»¥c (Re-index)"):
        st.cache_resource.clear()
        st.success("ÄÃ£ cáº­p nháº­t dá»¯ liá»‡u má»›i nháº¥t tá»« cÃ¡c nguá»“n!")

# Khá»Ÿi táº¡o bá»™ nÃ£o (Sá»­ dá»¥ng cache Ä‘á»ƒ khÃ´ng khá»Ÿi Ä‘á»™ng láº¡i má»—i láº§n chat)
if "orchestrator" not in st.session_state:
    with st.spinner("Äang khá»Ÿi Ä‘á»™ng bá»™ nÃ£o Agent..."):
        st.session_state.orchestrator = init_system()

# Quáº£n lÃ½ lá»‹ch sá»­ chat
if "messages" not in st.session_state:
    st.session_state.messages = []

# Hiá»ƒn thá»‹ cÃ¡c tin nháº¯n cÅ©
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- LUá»’NG Xá»¬ LÃ CHÃNH ---

if prompt := st.chat_input("Há»i tÃ´i vá» giÃ¡ vÃ ng, chÃ­nh sÃ¡ch cáº§m Ä‘á»“ hoáº·c báº£o hÃ nh..."):
    # 1. Hiá»ƒn thá»‹ cÃ¢u há»i cá»§a khÃ¡ch
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. Agent xá»­ lÃ½ (TÃ¬m nghiá»‡p vá»¥ -> Káº¿t ná»‘i dá»¯ liá»‡u -> Suy luáº­n)
    with st.chat_message("assistant"):
        with st.spinner("AI Ä‘ang truy xuáº¥t dá»¯ liá»‡u..."):
            try:
                # Gá»i bá»™ Ä‘iá»u phá»‘i Ä‘á»ƒ xá»­ lÃ½ cÃ¢u há»i
                response = st.session_state.orchestrator.handle_request(prompt)
                st.markdown(response)
                
                # LÆ°u vÃ o lá»‹ch sá»­
                st.session_state.messages.append({"role": "assistant", "content": response})
            except Exception as e:
                error_msg = f"ÄÃ£ xáº£y ra lá»—i há»‡ thá»‘ng: {str(e)}"
                st.error(error_msg)