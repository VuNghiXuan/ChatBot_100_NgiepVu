import streamlit as st
from dotenv import load_dotenv
import os

# Import c√°c th√†nh ph·∫ßn c·ªët l√µi
from core.llm_factory import LLMFactory
from core.orchestrator import Orchestrator

# 1. C·∫•u h√¨nh giao di·ªán v√† load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()
st.set_page_config(page_title="AI Ti·ªám V√†ng - Enterprise Agent", layout="wide")

# --- H√ÄM KH·ªûI T·∫†O H·ªÜ TH·ªêNG ---
def init_system(provider):
    """Kh·ªüi t·∫°o b·ªô n√£o c·ªßa h·ªá th·ªëng d·ª±a tr√™n nh√† cung c·∫•p ƒë∆∞·ª£c ch·ªçn"""
    try:
        # LLMFactory s·∫Ω t·ª± ƒë·ªông l·∫•y API Key t·ª´ .env t∆∞∆°ng ·ª©ng v·ªõi provider
        llm = LLMFactory.get_model(provider)
        # Kh·ªüi t·∫°o b·ªô ƒëi·ªÅu ph·ªëi
        return Orchestrator(llm)
    except Exception as e:
        st.error(f"L·ªói kh·ªüi t·∫°o h·ªá th·ªëng: {str(e)}")
        return None

# --- GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG (UI) ---

st.title("ü§ñ Tr·ª£ L√Ω AI Ti·ªám V√†ng ƒêa Nghi·ªáp V·ª•")
st.markdown("---")

# Sidebar c·∫•u h√¨nh
with st.sidebar:
    st.header("‚öôÔ∏è C·∫•u h√¨nh h·ªá th·ªëng")
    
    # B·ªï sung ch·ªçn nh√† cung c·∫•p LLM
    selected_provider = st.selectbox(
        "Ch·ªçn n√£o b·ªô AI (LLM Provider):",
        options=["Gemini", "Groq", "Ollama"],
        index=0,
        help="Gemini/Groq y√™u c·∫ßu Internet, Ollama ch·∫°y Offline tr√™n m√°y c·ª•c b·ªô."
    )
    
    # N√∫t c·∫≠p nh·∫≠t h·ªá th·ªëng khi ƒë·ªïi Provider ho·∫∑c Re-index d·ªØ li·ªáu
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üöÄ √Åp d·ª•ng AI"):
            st.session_state.orchestrator = init_system(selected_provider)
            st.success(f"ƒê√£ chuy·ªÉn sang {selected_provider}!")
    with col2:
        if st.button("üîÑ Re-index"):
            st.cache_resource.clear()
            st.success("ƒê√£ l√†m m·ªõi d·ªØ li·ªáu!")

    st.divider()
    st.info("Ch·∫ø ƒë·ªô: **Hybrid Mode** (File/DB/API Auto-detect)")

# Kh·ªüi t·∫°o b·ªô n√£o l·∫ßn ƒë·∫ßu (N·∫øu ch∆∞a c√≥ trong session_state)
if "orchestrator" not in st.session_state:
    with st.spinner(f"ƒêang kh·ªüi ƒë·ªông Agent v·ªõi {selected_provider}..."):
        st.session_state.orchestrator = init_system(selected_provider)

# Qu·∫£n l√Ω l·ªãch s·ª≠ chat
if "messages" not in st.session_state:
    st.session_state.messages = []

# Hi·ªÉn th·ªã c√°c tin nh·∫Øn c≈©
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- LU·ªíNG X·ª¨ L√ù CH√çNH ---

if prompt := st.chat_input("H·ªèi t√¥i v·ªÅ gi√° v√†ng, ch√≠nh s√°ch c·∫ßm ƒë·ªì ho·∫∑c b·∫£o h√†nh..."):
    # 1. Hi·ªÉn th·ªã c√¢u h·ªèi c·ªßa kh√°ch
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. Agent x·ª≠ l√Ω (T√¨m nghi·ªáp v·ª• -> K·∫øt n·ªëi d·ªØ li·ªáu -> Suy lu·∫≠n)
    with st.chat_message("assistant"):
        if st.session_state.orchestrator is None:
            st.error("H·ªá th·ªëng ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o. Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh .env v√† ch·ªçn l·∫°i AI.")
        else:
            with st.spinner(f"AI ({selected_provider}) ƒëang x·ª≠ l√Ω..."):
                try:
                    # G·ªçi b·ªô ƒëi·ªÅu ph·ªëi ƒë·ªÉ x·ª≠ l√Ω c√¢u h·ªèi
                    response = st.session_state.orchestrator.handle_request(prompt)
                    st.markdown(response)
                    
                    # L∆∞u v√†o l·ªãch s·ª≠
                    st.session_state.messages.append({"role": "assistant", "content": response})
                except Exception as e:
                    st.error(f"ƒê√£ x·∫£y ra l·ªói: {str(e)}")